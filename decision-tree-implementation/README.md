### Decision Tree Implementation using Scikit-Learn

**What’s This About?** - Hey there! This project is here to help you understand how to create and test a Decision Tree classifier using the well-known Iris flower dataset. If you’re just starting out in machine learning, this is a great place to get your feet wet with clear code and easy steps.

**Why Should You Care?** - Decision Trees are one of the simplest yet powerful tools in machine learning. This project will show you how to use them to classify data, perfect for beginners (including myself) wanting hands-on experience!

**Objective** - This project helps **you** implement and understand a Decision Tree Classifier using the famous Iris dataset.  
You’ll explore the whole process, from loading data to tuning your model and making sense of the results.

**What’s Inside?**
- decision_tree.ipynb - The Jupyter Notebook containing your code and results
- requirements.txt - All the packages you need to install (super easy!)
- Readme.md - Yep… this friendly guide you’re reading now.

**Dataset Used**  
Iris Dataset (built-in from `sklearn.datasets`):
- 150 records with 4 features: _sepal length, sepal width, petal length, petal width_
- 3 target classes: _Setosa, Versicolor, Virginica_

**How Do You Run This?**

1. Make sure you have Python installed (version 3.6 or above is good).
2. Open your terminal/command prompt and install dependencies:

ㅤㅤㅤ`pip install -r requirements.txt`

3. Fire up the Jupyter notebook and run the cells step-by-step:

ㅤㅤㅤ`jupyter notebook notebooks/decision_tree.ipynb`

4. Follow along as the notebook walks you through loading data, training the model, and checking how well it works.

**What Will You Learn?**
- How to load and explore a classic ML dataset
- How to train a Decision Tree classifier from scratch
- How to evaluate a model’s performance with clear metrics
- Some basic Python coding best practices for ML projects

**Need Help?** - No worries, I was just like you when I started. Take it slow, read the comments, Google stuff if you’re stuck. You got this!
